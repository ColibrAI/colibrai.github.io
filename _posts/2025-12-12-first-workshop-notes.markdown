---
layout: post
title:  "Notes from the First Workshop on Ecofeminist AI"
date:   2025-12-12
author: ColibrAI team
categories: blog
---
<div style="text-align:center;"><img src="/images/blog2.jpg" style="width:60%;"></div>

<p align="justify">
The first ColibrAI introductory meeting on Nov. 24 brought the group together to explore what it means to approach AI from a justice-oriented perspective. Using ecofeminism as our starting point, we explored the idea that AI is not just a technical system but a structure of power that determines whose voices matter, whose needs are prioritized, and whose lives or environments are made visible or ignored. Although AI often appears neutral, we discussed how it encodes social and political values, reproducing hierarchies that long predate the technology itself.
</p>
<p align="justify">
A central theme was what remains hidden in AI systems. Epistemic omission, drawing on Gayatri Spivak's idea of <b>epistemic violence</b>, helps describe how certain communities and ways of living come to fall outside the frame of mainstream AI design. We noted examples from healthcare and urban planning to smartphone and crash-test design, all reinforcing the idea that what is "never collected" shapes whose realities matter. We also examined privilege hazard, or how designers' structural ignorance becomes normalized in technological decisions.
</p>
<p align="justify">
We explored the many layers of invisible labor that sustain AI: resource extraction, manufacturing under hazardous conditions, massive data-center infrastructures, and the dispersed global workforce of annotators and moderators. We also discussed how technology companies increasingly take over roles traditionally held by educators, reshaping where authority and responsibility sit within learning environments. At the same time, we reflected on the hidden forms of labor that users themselves perform through everyday interactions with digital systems. Environmental impacts, from carbon emissions and water consumption to e-waste, were also framed not as side effects but as core features of current AI systems, often amplified by forms of green colonialism.
</p>
<p align="justify">
We then turned to ecofeminism as a way of reimagining AI through care, plurality, relationality, and justice rather than efficiency and extraction. We drew connections to Indigenous AI perspectives, feminist AI practices, and the need to move from individual ethics toward structural forms of justice. We reflected on unlearning dominant epistemologies, critically using or refusing AI, and imagining what consensual AI might look like. Ideas such as subversion, hacking, and "irritating" established systems emerged as creative strategies for shifting power.
</p>
<p align="justify">
We closed by linking these discussions to our shared project: developing an LLM-based storytelling platform to surface erased narratives around invisible labor, environmental harm, and data gaps. As we prepare for the upcoming sessions on decolonial and participatory AI, this meeting provided a solid and motivating starting point for the work ahead, strengthening the foundation for interdisciplinary collaboration within ColibrAI and for future projects at the intersection of computer science, education, and design.
</p>
