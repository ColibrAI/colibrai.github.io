---
layout: post
title:  "Second Workshop: Decolonize AI"
date:   2026-01-20
excerpt: The second ColibrAI meeting, led by Damstad, approached AI through a decolonial lens, questioning the Western-centric assumptions that shape both AI development and educational practice and examining the epistemological foundations of education, technology, and the idea of progress itself.
author: ColibrAI team
categories: blog
---
<div style="text-align:center;">
  <img src="/images/blog3.jpg" style="width:60%;">
  <div style="margin-top:-8px; font-size:0.9em; color:#555;">
    Michael Kwet, "Digital Colonialism: The Evolution of US Empire", Transnational Institute Longread
  </div>
</div>
<br>
<p align="justify">
The second ColibrAI meeting, led by Damstad, approached AI through a decolonial lens, questioning the Western-centric assumptions that shape both AI development and educational practice and examining the epistemological foundations of education, technology, and the idea of progress itself.
</p>
<p align="justify">
The conversation began with a fundamental question: what is education for? Educational research was described as having two core tasks: (1) the theoretical and empirical study of pedagogical practice, and (2) the development of proposals to shape or improve educational contexts. Yet education was not reduced to schooling or vocational training. The concept of Bildung foregrounds education as cultural formation and lifelong self-development. From this perspective, education becomes inseparable from broader societal transformations. This raised a crucial issue: in a world increasingly structured by digital technologies and AI, how are educational practices, institutions, and even notions of personhood being reshaped?
</p>
<p align="justify">
From this point, the discussion naturally expanded to digitalization and digitality. Instead of treating digitalization as a sequence of technological innovations, digitality was framed as a condition in which digital technologies are already deeply woven into everyday life. In this postdigital context, the focus shifts away from novelty and toward structural transformation. Digital media shape communication, social organization, perception, and self-understanding. AI, therefore, cannot be treated as a discrete technological breakthrough; it must be understood as part of a broader media ecology that reorganizes cultural and social life.
</p>
<p align="justify">
This broader view made it necessary to confront the material dimensions of digital systems. The apparent immateriality of “the cloud” and seamless interfaces conceals extensive global infrastructures. From extractive mining and industrial production to data centers and satellite networks, digital technologies are grounded in material processes that are unevenly distributed across the globe. The digital is neither neutral nor weightless. It is entangled with environmental costs, labor exploitation, and geopolitical inequalities. Recognizing this materiality disrupts narratives of frictionless innovation and exposes the structural conditions underpinning AI systems.
</p>
<p align="justify">
These material considerations led directly to a discussion of sustainability and the future. Drawing on established definitions of sustainable development, the session emphasized justice across generations as well as within the present. Sustainability was framed not as a question of technical efficiency alone, but as a normative and political issue: how should present needs be balanced with those of future generations? Competing logics such as efficiency, sufficiency, and consistency were examined in relation to digital technologies. In this light, AI becomes a force that not only predicts the future but actively shapes collective imaginaries of what the future can or should be.
</p>
<p align="justify">
The focus on sustainability also required attention to the full lifecycle of digital technologies, from development and production to use, disposal, and recycling. Questions emerged about exploitative labor conditions, unequal access to digital infrastructure, disparities in digital skills, linguistic dominance online, and the ongoing export of electronic waste to the Global South. The so-called digital divide appeared not simply as a lack of connectivity, but as a structural configuration of power, knowledge, and resources. AI development, in this context, is inseparable from colonial histories and contemporary global asymmetries.
</p>
<p align="justify">
This structural analysis was deepened through an examination of the historical entanglement between media technologies and colonial narratives. European science and technological advancement were historically framed as enlightenment and universal progress, while writing, cartography, surveying, and documentation operated as instruments of governance and control. Literacy was elevated as a marker of intelligence, and certain languages and representational systems were privileged over others. These historical dynamics illuminate how contemporary AI systems may continue to privilege specific datasets, epistemologies, and linguistic norms while marginalizing others, often under the appearance of neutrality.
</p>
<p align="justify">
Alternative cartographic practices provided a compelling illustration of this point. Mapping is not a neutral act of depiction; it is an act of world-making. Maps construct hierarchies, perspectives, and boundaries. In a similar way, AI systems participate in world-making through data selection, classification, and prediction. They do not merely mirror reality; they help produce it. This insight underscores the importance of interrogating the epistemological assumptions embedded in data collection, modeling, and evaluation processes.
</p>
<p align="justify">
Against this backdrop, participation itself came under scrutiny. While digital infrastructures are frequently associated with democratization and openness, they often reproduce asymmetries of knowledge, resources, and influence. The idea of “Potemkin AI”, systems that appear fully automated while relying on hidden human labor, exemplifies how technological narratives can obscure underlying structures. Participation risks becoming performative when it leaves foundational power relations untouched. In response, the notion of “coliberation” was proposed as a more demanding alternative: not participation as spectacle, but shared critical responsibility and transformative engagement.
</p>
<p align="justify">
The session concluded by returning to the question of the future. As algorithmic prediction becomes increasingly operational, it reshapes decision-making in the present. Prediction shifts from statistical estimation to preemptive action. In educational contexts, this development carries significant consequences. Predictive analytics and automated assessment systems may channel trajectories in advance, narrowing rather than expanding the space of possibility that education is meant to cultivate.
</p>
